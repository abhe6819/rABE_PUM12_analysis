---
title: "PUM2_multivarModeling"
author: "Abby Hein"
date: "2022-10-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/FloorRotation_Fall22/")
library(dplyr)
library(ggplot2)
library(wesanderson)
library(tidyr)
library(seqinr)
library(Biostrings)
library(randomForest)
library(caret)
library(ROCR)
library(tune)
```

### Linear Regression
## Machine learning
```{r}
PUM2_bedClosest_exonDPfilt <-filter(PUM2_bedClosest, within_Window=='a', avgExonDP>50)
#PUM2_bedClosest_exonDPfilt <-filter(PUM2_bedClosest, within_Window=='a', padj<0.05)

sum(is.na(PUM2_bedClosest_exonDPfilt$diffratios))

sum(is.na(PUM2_bedClosest$diffratios))
ddG_linreg <- lm(formula = diffratios ~ ddG, data = PUM2_bedClosest_exonDPfilt)
summary(ddG_linreg)
#residuals appear random (yay)
plot(residuals(ddG_linreg))
chisq.test(table(residuals(ddG_linreg)))
```


```{r}
#split data into testing and training datasets
set.seed(2784)
## assign random row numbers
rowNum <- runif(nrow(PUM2_bedClosest_exonDPfilt))
##split into 80% training 20% testing
PUM2_train <- subset(PUM2_bedClosest_exonDPfilt, rowNum < 0.8)
PUM2_test <- subset(PUM2_bedClosest_exonDPfilt, rowNum >= 0.8)
ddG_lmModel <- lm(diffratios ~ ., data = PUM2_train[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")])
summary(ddG_lmModel)
ddG_lmFineModel <- lm(diffratios ~ numAdjMotif+ddG+avgExonDP+(Ts=="C")+(Ts=="G")+Distance_to_motif, data = PUM2_train[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")])
summary(ddG_lmFineModel)
# Test models
lmModel_prob <- predict.lm(ddG_lmModel, newdata = PUM2_test)
PUM2_eval<-cbind(PUM2_test$diffratios,lmModel_prob)
sqrt(mean((PUM2_eval[,1]- PUM2_eval[,2])^2))

lmFineModel_prob <- predict.lm(ddG_lmFineModel, newdata = PUM2_test)
PUM2_fine_eval<-cbind(PUM2_test,lmFineModel_prob)
sqrt(mean((PUM2_fine_eval$diffratios- PUM2_fine_eval$lmFineModel_prob)^2))

plot(x= PUM2_fine_eval$lmFineModel_prob, y= PUM2_fine_eval$diffratios)
abline(a= 0, b=1, col="red")
cor.test(x= PUM2_fine_eval$lmFineModel_prob, y= PUM2_fine_eval$diffratios)
PUM2_fine_eval<- pivot_longer(PUM2_fine_eval, c("diffratios","lmFineModel_prob"), names_to = "Pred_or_Obs", values_to = "rate")

#plot pred vs obs
#filter(PUM2_bedClosest, within_Window=='a', avgExonDP>50, numAdjMotif<=0, ss_ddG<10) %>% 
  ggplot(PUM2_fine_eval, aes(x = ddG, y = rate, group = Pred_or_Obs, color=Pred_or_Obs))+
    geom_point(alpha=0.1)+
    geom_smooth(method = "lm",  aes(group= Pred_or_Obs,color=Pred_or_Obs))+
    scale_y_log10()
```

### Random Forest 
```{r}
#split data into testing and training datasets
set.seed(2785)
## assign random row numbers
rowNum <- runif(nrow(PUM2_bedClosest_exonDPfilt))
##split into 80% training 20% testing
PUM2_train <- subset(PUM2_bedClosest_exonDPfilt, rowNum < 0.8)
PUM2_test <- subset(PUM2_bedClosest_exonDPfilt, rowNum >= 0.8)

##long to run
#PUM2rf <- randomForest(diffratios~., data=PUM2_train[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")], proximity=TRUE)
print(PUM2rf)
PUM2_train <- PUM2_train[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")]
##long to run
#mtry <- tuneRF(PUM2_train[-1],PUM2_train$diffratios, ntreeTry=500,stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
#best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
print(best.m)

importance(PUM2rf)
varImpPlot(PUM2rf)

p1 <- predict(PUM2rf, PUM2_train[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")])

#PUM2rf <- randomForest(diffratios~., mtry=best.m, data=PUM2_train[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")], proximity=TRUE)
#print(PUM2rf)
#importance(PUM2rf)
#varImpPlot(PUM2rf)

PUM2_test<-PUM2_test[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")]
pred1=predict(PUM2rf, newdata = PUM2_test)
PUM2_test<-cbind(PUM2_test,pred1)
print("PUM2 random forest mean squared error:")
sqrt(mean((PUM2_test$diffratios- PUM2_test$pred1)^2))

ggplot(PUM2_test, aes(x=diffratios, y=pred1, color=abs(diffratios- pred1)))+
  geom_point(alpha = 0.4)+
  geom_abline(a= 0, b=1, col="maroon")+
  scale_colour_viridis_c(option = "viridis",direction = -1)+
  theme_minimal()
cor.test(x= PUM2_test$diffratios, y= PUM2_test$pred1)
PUM2_test<- pivot_longer(PUM2_test, c("diffratios","pred1"), names_to = "Pred_or_Obs", values_to = "rate")
#plot pred vs obs
#filter(PUM2_bedClosest, within_Window=='a', avgExonDP>50, numAdjMotif<=0, ss_ddG<10) %>% 
  ggplot(PUM2_test, aes(x = ddG, y = rate, group = Pred_or_Obs, color=Pred_or_Obs))+
    geom_point(alpha=0.1)+
    geom_smooth(method = "lm",  aes(group= Pred_or_Obs,color=Pred_or_Obs))+
    scale_y_log10()
```

### PUM1rf to model PUM2
```{r}
P2dat <- PUM2_bedClosest_exonDPfilt[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")]
pred2=predict(PUM1rf, newdata = P2dat)
P2dat<-cbind(P2dat,pred2)
sqrt(mean((P2dat$diffratios- P2dat$pred2)^2))

ggplot(P2dat, aes(x=diffratios, y=pred2, color=abs(diffratios- pred2)))+
  geom_point(alpha= 0.5)+
  geom_abline(a= 0, b=1, col="maroon")+
  scale_colour_viridis_c(option = "viridis",direction = -1)+
  theme_minimal()
  
cor.test(x= P2dat$diffratios, y= P2dat$pred2)
P2dat<- pivot_longer(P2dat, c("diffratios","pred2"), names_to = "Pred_or_Obs", values_to = "rate")
#plot pred vs obs
#filter(PUM1_bedClosest, within_Window=='a', avgExonDP>50, numAdjMotif<=0, ss_ddG<10) %>% 
  ggplot(P2dat, aes(x = ddG, y = rate, group = Pred_or_Obs, color=Pred_or_Obs))+
    geom_point(alpha=0.1)+
    geom_smooth(method = "lm",  aes(group= Pred_or_Obs,color=Pred_or_Obs))+
    scale_y_log10()
```



### PUM2 ddG random forest
```{r, eval=FALSE}
#split data into testing and training datasets
set.seed(2785)
## assign random row numbers
rowNum <- runif(nrow(PUM2_bedClosest_exonDPfilt))
##split into 80% training 20% testing
PUM2_train <- subset(PUM2_bedClosest_exonDPfilt, rowNum < 0.8)
PUM2_test <- subset(PUM2_bedClosest_exonDPfilt, rowNum >= 0.8)

PUM2_train <- PUM2_train[,c("Distance_to_motif","Ts","ddG","numAdjMotif","diffratios","avgExonDP")]
##long to run ()
#PUM2rf_ddG <- randomForest(ddG~., data=PUM2_train, proximity=TRUE)
print(PUM2rf_ddG)

##long to run
#mtry_ddG2 <- tuneRF(PUM2_train[-1],PUM2_train$ddG, ntreeTry=500,stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
#best.m_ddG2 <- mtry_ddG2[mtry_ddG2[, 2] == min(mtry_ddG2[, 2]), 1]
print(mtry_ddG2)
print(best.m_ddG2)

importance(PUM2rf_ddG)
varImpPlot(PUM2rf_ddG)

p1 <- predict(PUM2rf_ddG, PUM2_train[,c("Distance_to_motif","Ts","ddG","numAdjMotif","diffratios","avgExonDP")])

##long to run
#PUM2rf_ddG <- randomForest(ddD~., mtry=best.m_ddG2, data=PUM2_train[,c("Distance_to_motif","Ts","ddG","ss_ddG","numAdjMotif","diffratios","avgExonDP")], proximity=TRUE)
#print(PUM2rf_ddG)
#importance(PUM2rf_ddG)
#varImpPlot(PUM2rf_ddG)

PUM2_test<-PUM2_test[,c("Distance_to_motif","Ts","ddG","numAdjMotif","diffratios","avgExonDP")]
pred1=predict(PUM2rf_ddG, newdata = PUM2_test)
PUM2_test<-cbind(PUM2_test,pred1)
print("PUM2 random forest Mean squared error:")
sqrt(mean((PUM2_test$ddG- PUM2_test$pred1)^2))

ggplot(PUM2_test, aes(x=ddG, y=pred1, color=abs(ddG- pred1)))+
  geom_point(alpha = 0.4)+
  geom_abline(a= 0, b=1, col="maroon")+
  scale_colour_viridis_c(option = "viridis",direction = -1)+
  theme_minimal()

cor.test(x= PUM2_test$ddG, y= PUM2_test$pred1)
PUM2_test<- pivot_longer(PUM2_test, c("ddG","pred1"), names_to = "Pred_or_Obs", values_to = "affinity")
#plot pred vs obs
#filter(PUM2_bedClosest, within_Window=='a', avgExonDP>50, numAdjMotif<=0, ss_ddG<10) %>% 
  ggplot(PUM2_test, aes(x = diffratios, y = affinity, group = Pred_or_Obs, color=Pred_or_Obs))+
    geom_point(alpha=0.1)+
    geom_smooth(method = "lm",  aes(group= Pred_or_Obs,color=Pred_or_Obs))+
    scale_x_log10()
```

